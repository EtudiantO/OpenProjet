import os
import csv
from bs4 import BeautifulSoup
import requests
import urllib.request

os.mkdir('Books')
os.mkdir('LesImages')

homepage = "https://books.toscrape.com/"
def get_all_categories():
    reponse = requests.get(homepage)
    soup = BeautifulSoup(reponse.content.decode("utf-8", "ignore"), features="html.parser")
    categories=soup.find('div',{'class':'side_categories'}).findAll('a')

    data={}
    for category in categories[1:]:

        data[category.text.strip()]=homepage+category['href']

    return data

def get_all_books(url):

        list=[]
        reponse=requests.get(url)
        soup = BeautifulSoup(reponse.content.decode("utf-8", "ignore"), features="html.parser")
        articles = soup.find_all("article")
        for article in articles:
            livre_url=(homepage+"catalogue/"+article.find('a')['href']).replace("../","")
            list.append(livre_url)
        next_page=soup.find("li",{"class": "next"})
        if next_page:

          url_page=next_page.find("a")['href']
          url=url.split("/")
          url[-1]=url_page
          url="/".join(url)
          list+=get_all_books(url)
        return list


def create_csv(name):
    with open("Books/" + name + ".csv", 'w', newline='') as fichier:
        entetes = [
            "product_page_url",
            "universal_product_code",
            "title",
            "price_including_tax",
            "price_excluding_tax",
            "number_available",
            "product_description",
            "category",
            "reviews_rating",
            "image_url",
            "image_name",
        ]
        ligne_entetes = ";".join(entetes) + "\n"
        fichier.write(ligne_entetes)

def get_data(url):

    reponse = requests.get(url)
    soup = BeautifulSoup(reponse.content.decode("utf-8", "ignore"), features="html.parser")
    infos = soup.find_all('td')
    titre=soup.find('h1').text
    description=soup.find('meta', {'name': 'description'})['content']
    reviews_rating=soup.find('p',{'class':'star-rating'})['class'][1]
    image_url=soup.find('img')['src']
    image_name=soup.find('img')['alt']

    l= [
        url,
        infos[0].text,
        titre,
        infos[3].text,
        infos[2].text,
        infos[5].text,
        description.replace("\n","").replace(";", ","),
        name,
        reviews_rating,
        homepage+image_url.replace("../",""),
        image_name
     ]

    with open("Books/"+ name+".csv",'a',encoding="utf-8", newline='') as fichier:
                mylist =";".join(l)+ "\n"
                fichier.write(mylist)
    return l
def get_image(url,name):
    urllib.request.urlretrieve(
        url,
        "LesImages/" + name.replace(".", "")
            .replace(":", "")
            .replace("*", "")
            .replace("?", "")
            .replace('"', "")
            .replace("#", "")
            .replace("1", "")
            .replace(" ","")
            .replace(",", "")
            .replace("/","")
            + ".jpg"
            )

categories = get_all_categories()
for name, url in categories.items():
    book_urls = get_all_books(url)
    create_csv(name)
    for book_url in book_urls:
        data=get_data(book_url)
        get_image(data[-2],data[-1])








